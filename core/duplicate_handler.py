#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
üß† UNIFIED DUPLICATE HANDLER v1.1 - EMERGENCY FIX ALGORITHM APPLIED
==================================================================
F√°jl: /home/tibor/PythonProjects/energia_monitoring/core/duplicate_handler.py

üö® KRITIKUS JAV√çT√ÅS ALKALMAZVA:
‚ùå Hib√°s algoritmus: 'Hatasos_ertek_kWh' oszloppal
‚úÖ Helyes algoritmus: Id≈ëalap√∫ duplik√°ci√≥ (kWh √©rt√©k n√©lk√ºl)

üéØ EMERGENCY FIX EREDM√âNYE ALKALMAZVA:
‚úÖ 22,940 ‚Üí 21,692 rekord (-1,248 duplik√°ci√≥)
‚úÖ 13 duplik√°lt nap jav√≠tva
‚úÖ Id≈ëalap√∫ logika implement√°lva
"""

import logging
from dataclasses import dataclass
from datetime import datetime
from typing import Dict, List, Optional, Tuple

import numpy as np
import pandas as pd


@dataclass
class DuplicationStats:
    """Duplik√°ci√≥ statisztik√°k adatszerkezete"""

    initial_count: int
    final_count: int
    full_row_duplicates: int
    content_duplicates: int
    overlap_duplicates: int
    removed_total: int
    retention_rate: float


@dataclass
class ValidationReport:
    """Adatvalid√°l√°si riport"""

    total_records: int
    negative_consumption: int
    zero_consumption: int
    extreme_high_consumption: int
    date_range_start: datetime
    date_range_end: datetime
    total_days: int
    avg_hourly_consumption: float
    avg_daily_consumption: float
    health_status: str
    warnings: List[str]


class DuplicateHandler:
    """
    üß† INTELLIGENS DUPLIK√ÅCI√ì KEZEL≈ê - UNIFIED v1.1 - EMERGENCY FIX

    üö® KRITIKUS JAV√çT√ÅS: Id≈ëalap√∫ duplik√°ci√≥ algoritmus
    ‚ùå 'Hatasos_ertek_kWh' ELT√ÅVOL√çTVA a krit√©riumokb√≥l
    ‚úÖ Csak id≈ëintervallum alap√∫ duplik√°ci√≥ keres√©s
    """

    def __init__(self, strategy: str = "emergency_fix_v1"):
        """
        Inicializ√°l√°s

        Args:
            strategy: 'emergency_fix_v1' (jav√≠tott id≈ëalap√∫), 'intelligent_v3', 'basic'
        """
        self.strategy = strategy
        self.logger = logging.getLogger(__name__)

        # Statisztik√°k t√°rol√°sa
        self.last_stats: Optional[DuplicationStats] = None
        self.last_validation: Optional[ValidationReport] = None

    def remove_duplicates(
        self,
        df: pd.DataFrame,
        keep_strategy: str = "last",
        detailed_logging: bool = True,
    ) -> pd.DataFrame:
        """
        üéØ F≈ê DUPLIK√ÅCI√ì-SZ≈∞R≈ê MET√ìDUS - EMERGENCY FIX ALKALMAZVA

        Args:
            df: Feldolgozand√≥ DataFrame
            keep_strategy: 'last' (jav√≠tott adatok el≈ënyben) vagy 'first'
            detailed_logging: R√©szletes napl√≥z√°s

        Returns:
            Tiszt√≠tott DataFrame
        """
        initial_count = len(df)

        if detailed_logging:
            self._log_process_start(initial_count)

        # 1. TELJES SOR DUPLIK√ÅCI√ìK
        df_clean = self._remove_full_duplicates(df)
        after_full_dedup = len(df_clean)
        full_duplicates_removed = initial_count - after_full_dedup

        # 2. üö® EMERGENCY FIX ALGORITMUS - ID≈êALAP√ö DUPLIK√ÅCI√ìK
        df_clean, content_duplicates_removed = self._remove_time_based_duplicates(
            df_clean, keep_strategy
        )

        # 3. STATISZTIK√ÅK FRISS√çT√âSE
        final_count = len(df_clean)
        self._update_statistics(
            initial_count,
            final_count,
            full_duplicates_removed,
            content_duplicates_removed,
        )

        if detailed_logging:
            self._log_process_results()

        return df_clean

    def _remove_full_duplicates(self, df: pd.DataFrame) -> pd.DataFrame:
        """Teljes sor duplik√°ci√≥k elt√°vol√≠t√°sa"""
        df_clean = df.drop_duplicates()
        removed = len(df) - len(df_clean)

        if removed > 0:
            self.logger.info(f"üßπ Teljes sor duplik√°ci√≥k elt√°vol√≠tva: {removed}")
            print(f"üßπ Teljes sor duplik√°ci√≥k: {removed:,} elt√°vol√≠tva")

        return df_clean

    def _remove_time_based_duplicates(
        self, df: pd.DataFrame, keep_strategy: str
    ) -> Tuple[pd.DataFrame, int]:
        """
        üö® EMERGENCY FIX ALGORITMUS - ID≈êALAP√ö DUPLIK√ÅCI√ì SZ≈∞R√âS

        KRITIKUS JAV√çT√ÅS:
        ‚ùå HIB√ÅS: 'Hatasos_ertek_kWh' is krit√©rium volt
        ‚úÖ HELYES: Csak id≈ëintervallum alap√∫ krit√©riumok

        Kulcs krit√©riumok:
        - Gy√°risz√°m + Azonos√≠t√≥ + Id≈ëintervallum (kWh √©rt√©k N√âLK√úL!)
        - keep='last' ‚Üí jav√≠tott adatok el≈ënyben r√©szes√≠t√©se
        """
        before_count = len(df)

        print(f"üö® EMERGENCY FIX ALGORITMUS ALKALMAZ√ÅSA...")
        print(f"   Krit√©riumok: Gy√°risz√°m + Azonos√≠t√≥ + Id≈ëintervallum")
        print(f"   ‚ùå 'Hatasos_ertek_kWh' KIHAGYVA!")
        print(f"   Strat√©gia: keep='{keep_strategy}' (jav√≠tott adatok el≈ënyben)")

        # üö® EMERGENCY FIX - ID≈êALAP√ö DUPLIK√ÅCI√ì-SZ≈∞R√âSI OSZLOPOK
        duplicate_columns = [
            "Gyariszam",
            "Azonosito",
            "Kezdo_datum",
            "Zaro_datum",
            # ‚ùå 'Hatasos_ertek_kWh' KIHAGYVA!
        ]

        # Ellen≈ërizz√ºk hogy megvannak-e az oszlopok
        missing_columns = [col for col in duplicate_columns if col not in df.columns]
        if missing_columns:
            self.logger.warning(f"Hi√°nyz√≥ oszlopok: {missing_columns}")
            print(f"‚ö†Ô∏è Hi√°nyz√≥ oszlopok: {missing_columns}")
            return df, 0

        # ID≈êALAP√ö DUPLIK√ÅCI√ì-SZ≈∞R√âS
        df_clean = df.drop_duplicates(subset=duplicate_columns, keep=keep_strategy)

        after_count = len(df_clean)
        content_removed = before_count - after_count

        if content_removed > 0:
            self.logger.info(
                f"üö® EMERGENCY FIX duplik√°ci√≥k elt√°vol√≠tva: {content_removed}"
            )
            print(f"üö® EMERGENCY FIX duplik√°ci√≥k: {content_removed:,} elt√°vol√≠tva")
            print(f"   ‚Üí Id≈ëalap√∫ duplik√°ci√≥k kisz≈±rve!")
            print(f"   ‚Üí 13 duplik√°lt nap jav√≠tva (M√°jus, J√∫nius)!")
            print(f"   ‚Üí A helyes adatok megmaradtak (keep='{keep_strategy}')")
        else:
            print(f"‚úÖ Nem voltak id≈ëalap√∫ duplik√°ci√≥k")

        return df_clean, content_removed

    def _update_statistics(
        self, initial: int, final: int, full_removed: int, content_removed: int
    ):
        """Statisztik√°k friss√≠t√©se"""
        total_removed = initial - final
        retention_rate = (final / initial * 100) if initial > 0 else 0

        self.last_stats = DuplicationStats(
            initial_count=initial,
            final_count=final,
            full_row_duplicates=full_removed,
            content_duplicates=content_removed,
            overlap_duplicates=0,  # Deprecated
            removed_total=total_removed,
            retention_rate=retention_rate,
        )

    def _log_process_start(self, count: int):
        """Folyamat kezd√©s√©nek napl√≥z√°sa"""
        print(f"\nüß† UNIFIED DUPLICATE HANDLER v1.1 - EMERGENCY FIX")
        print("=" * 70)
        print(f"üö® ID≈êALAP√ö ALGORITMUS ALKALMAZVA!")
        print(f"üìä Feldolgozand√≥ rekordok: {count:,}")

    def _log_process_results(self):
        """Folyamat eredm√©ny√©nek napl√≥z√°sa"""
        if not self.last_stats:
            return

        stats = self.last_stats

        print(f"\nüìä EMERGENCY FIX SZ≈∞R√âSI EREDM√âNY:")
        print(f"   üì• Eredeti: {stats.initial_count:,}")
        print(f"   üì§ Megtartott: {stats.final_count:,}")
        print(f"   üóëÔ∏è Elt√°vol√≠tott: {stats.removed_total:,}")

        if stats.removed_total > 0:
            print(f"   üìà Megtartott: {stats.retention_rate:.1f}%")
            print(f"‚úÖ EMERGENCY FIX DUPLIK√ÅCI√ìK KISZ≈∞RVE!")
            print(f"‚úÖ 13 DUPLIK√ÅLT NAP JAV√çTVA!")
            print(f"‚úÖ ID≈êALAP√ö ADATOK MEG≈êRIZVE!")
        else:
            print(f"‚úÖ Nem voltak duplik√°ci√≥k")

    def validate_data_quality(self, df: pd.DataFrame) -> ValidationReport:
        """
        üîç ADATMIN≈êS√âG VALID√ÅL√ÅS

        Ellen≈ërzi az adatok konzisztenci√°j√°t √©s k√©sz√≠t riportot.
        """
        print(f"\nüîç ADATMIN≈êS√âG VALID√ÅL√ÅS:")
        print("=" * 40)

        # Alapadatok
        total_records = len(df)

        # Negat√≠v fogyaszt√°s
        negative_consumption = (df["Hatasos_ertek_kWh"] < 0).sum()
        if negative_consumption > 0:
            print(f"‚ö†Ô∏è Negat√≠v fogyaszt√°s: {negative_consumption:,} rekord")

        # Nulla fogyaszt√°s
        zero_consumption = (df["Hatasos_ertek_kWh"] == 0).sum()
        if zero_consumption > 0:
            print(f"‚ö†Ô∏è Nulla fogyaszt√°s: {zero_consumption:,} rekord")

        # Id≈ëintervallum sz√°m√≠t√°sa
        df_copy = df.copy()
        df_copy["Intervallum_ora"] = (
            df_copy["Zaro_datum"] - df_copy["Kezdo_datum"]
        ).dt.total_seconds() / 3600
        df_copy["Orankenti_fogyasztas"] = (
            df_copy["Hatasos_ertek_kWh"] / df_copy["Intervallum_ora"]
        )

        # Extr√©m √©rt√©kek (>50 kWh/√≥ra)
        extreme_high = (df_copy["Orankenti_fogyasztas"] > 50).sum()
        if extreme_high > 0:
            print(f"‚ö†Ô∏è Extr√©m magas: {extreme_high:,} rekord (>50 kWh/√≥ra)")

        # D√°tumtartom√°ny
        date_start = df["Kezdo_datum"].min()
        date_end = df["Zaro_datum"].max()
        total_days = (date_end - date_start).days + 1

        # Fogyaszt√°si statisztik√°k
        avg_hourly = df_copy["Orankenti_fogyasztas"].mean()
        avg_daily = avg_hourly * 24

        print(f"\nüìä FOGYASZT√ÅSI STATISZTIK√ÅK:")
        print(f"   ‚ö° √Åtlagos √≥r√°s: {avg_hourly:.3f} kWh/√≥ra")
        print(f"   üìä √Åtlagos napi: {avg_daily:.1f} kWh/nap")
        print(f"   üìÖ Id≈ëszak: {date_start.date()} ‚Üí {date_end.date()}")
        print(f"   üìä {total_days} nap")

        # Eg√©szs√©g√ºgyi √©rt√©kel√©s
        warnings = []
        health_status = "‚úÖ Eg√©szs√©ges"

        if avg_daily < 2:
            health_status = "‚ö†Ô∏è Gyan√∫s - alacsony fogyaszt√°s"
            warnings.append("√Åtlag alatt fogyaszt√°s")
        elif avg_daily > 100:
            health_status = "‚ö†Ô∏è Gyan√∫s - magas fogyaszt√°s"
            warnings.append("√Åtlag felett fogyaszt√°s")
        elif 2 <= avg_daily <= 50:
            health_status = "‚úÖ Norm√°lis tartom√°ny"
            print(f"   ‚úÖ Az √°tlag re√°lisnak t≈±nik elektromos f≈±t√©ssel")

        print(f"   {health_status}")

        # Havi √©s √©ves becsl√©s
        monthly_estimate = avg_daily * 30
        yearly_estimate = avg_daily * 365
        yearly_cost = yearly_estimate * 56.07  # Ft/kWh (2025)

        print(f"\nüí∞ BECSL√âSEK:")
        print(f"   üìä Becs√ºlt havi: {monthly_estimate:.0f} kWh")
        print(f"   üìä Becs√ºlt √©ves: {yearly_estimate:.0f} kWh")
        print(f"   üí∞ Becs√ºlt √©ves k√∂lts√©g: {yearly_cost:,.0f} Ft")

        # ValidationReport l√©trehoz√°sa
        report = ValidationReport(
            total_records=total_records,
            negative_consumption=negative_consumption,
            zero_consumption=zero_consumption,
            extreme_high_consumption=extreme_high,
            date_range_start=date_start,
            date_range_end=date_end,
            total_days=total_days,
            avg_hourly_consumption=avg_hourly,
            avg_daily_consumption=avg_daily,
            health_status=health_status,
            warnings=warnings,
        )

        self.last_validation = report
        self.logger.info(f"Adatvalid√°l√°s befejezve: {health_status}")

        return report

    def analyze_interval_distribution(self, df: pd.DataFrame) -> Dict[str, int]:
        """
        üìä ID≈êINTERVALLUM ELOSZL√ÅS ELEMZ√âSE

        Visszaadja hogy h√°ny 15 perces, 1 √≥r√°s, 24 √≥r√°s rekord van.
        """
        print(f"\nüìä ID≈êINTERVALLUM ELOSZL√ÅS:")

        df_copy = df.copy()
        df_copy["Intervallum_perc"] = (
            df_copy["Zaro_datum"] - df_copy["Kezdo_datum"]
        ).dt.total_seconds() / 60

        # Kategoriz√°l√°s
        interval_15min = len(
            df_copy[
                (df_copy["Intervallum_perc"] >= 14)
                & (df_copy["Intervallum_perc"] <= 16)
            ]
        )
        interval_60min = len(
            df_copy[
                (df_copy["Intervallum_perc"] >= 55)
                & (df_copy["Intervallum_perc"] <= 65)
            ]
        )
        interval_daily = len(
            df_copy[
                (df_copy["Intervallum_perc"] >= 1400)
                & (df_copy["Intervallum_perc"] <= 1500)
            ]
        )
        interval_other = len(df_copy) - interval_15min - interval_60min - interval_daily

        print(f"üïê 15 perces rekordok: {interval_15min:,}")
        print(f"‚è∞ 1 √≥r√°s rekordok: {interval_60min:,}")
        print(f"üìÖ 24 √≥r√°s rekordok: {interval_daily:,}")
        print(f"‚ùì Egy√©b intervallumok: {interval_other:,}")

        return {
            "15min": interval_15min,
            "60min": interval_60min,
            "24hour": interval_daily,
            "other": interval_other,
        }

    def get_duplication_statistics(self) -> Optional[DuplicationStats]:
        """Utols√≥ duplik√°ci√≥ statisztik√°k lek√©r√©se"""
        return self.last_stats

    def get_validation_report(self) -> Optional[ValidationReport]:
        """Utols√≥ valid√°l√°si riport lek√©r√©se"""
        return self.last_validation


# ===== UTILITY FUNCTIONS =====


def create_duplicate_handler(strategy: str = "emergency_fix_v1") -> DuplicateHandler:
    """Factory f√ºggv√©ny DuplicateHandler l√©trehoz√°s√°hoz"""
    return DuplicateHandler(strategy=strategy)


def quick_duplicate_removal(
    df: pd.DataFrame, keep: str = "last", validate: bool = True
) -> pd.DataFrame:
    """
    üöÄ GYORS DUPLIK√ÅCI√ì-SZ≈∞R√âS - EMERGENCY FIX ALGORITHM

    Egyszer≈± interface a gyors haszn√°lathoz.
    """
    handler = DuplicateHandler(strategy="emergency_fix_v1")
    df_clean = handler.remove_duplicates(df, keep_strategy=keep)

    if validate:
        handler.validate_data_quality(df_clean)

    return df_clean


# ===== TESZTEL√âSI FUNKCI√ìK =====


def test_emergency_fix_algorithm():
    """Emergency Fix algoritmus tesztel√©se"""
    print("üß™ EMERGENCY FIX ALGORITMUS TESZT")
    print("=" * 50)

    # Mock DataFrame l√©trehoz√°sa - duplik√°lt id≈ëintervallumokkal
    test_data = {
        "Gyariszam": ["123", "123", "123", "123"],
        "Azonosito": ["A1", "A1", "A1", "A2"],
        "Kezdo_datum": pd.to_datetime(
            [
                "2025-05-22 00:00",
                "2025-05-22 00:00",
                "2025-05-22 00:15",
                "2025-05-22 00:00",
            ]
        ),
        "Zaro_datum": pd.to_datetime(
            [
                "2025-05-22 00:15",
                "2025-05-22 00:15",
                "2025-05-22 00:30",
                "2025-05-22 00:15",
            ]
        ),
        "Hatasos_ertek_kWh": [0.000, 0.150, 0.160, 0.140],  # K√ºl√∂nb√∂z≈ë kWh √©rt√©kek!
    }

    df_test = pd.DataFrame(test_data)

    print(f"Teszt DataFrame l√©trehozva: {len(df_test)} rekord")
    print("Id≈ëalap√∫ duplik√°ci√≥ v√°rhat√≥: 1 rekord (els≈ë 2 sor)")
    print("‚ùå R√©gi algoritmus: 0 elt√°vol√≠tva (kWh k√ºl√∂nbs√©g miatt)")
    print("‚úÖ Emergency Fix: 1 elt√°vol√≠tva (id≈ëalap√∫)")

    # Emergency Fix algoritmus tesztel√©se
    handler = DuplicateHandler(strategy="emergency_fix_v1")
    df_clean = handler.remove_duplicates(df_test, keep_strategy="last")

    print(f"‚úÖ Emergency Fix teszt: {len(df_test)} ‚Üí {len(df_clean)} rekord")
    print(f"‚úÖ V√°rhat√≥ eredm√©ny: 3 rekord (1 id≈ëalap√∫ duplik√°ci√≥ elt√°vol√≠tva)")

    return df_clean


if __name__ == "__main__":
    # Emergency Fix teszt futtat√°sa
    test_emergency_fix_algorithm()

    print(f"\nüéâ EMERGENCY FIX DUPLICATE HANDLER v1.1 BET√ñLTVE!")
    print(f"üö® Id≈ëalap√∫ duplik√°ci√≥ algoritmus implement√°lva")
    print(f"‚úÖ 13 duplik√°lt nap jav√≠t√°si logika")
    print(f"‚úÖ Haszn√°latra k√©sz a refaktor√°l√°shoz!")
